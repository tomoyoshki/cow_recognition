{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import numpy as np \n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import image_slicer\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# load the COCO dataset category names\n",
    "# we will use the same list for this notebook\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "DESIRED_CLASS = [\n",
    "    'cat',\n",
    "    'dog',\n",
    "    'horse',\n",
    "    'sheep',\n",
    "    'cow',\n",
    "    'elephant',\n",
    "    'bear',\n",
    "    'zebra',\n",
    "    'giraffe',\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, confidence):\n",
    "  \"\"\"\n",
    "  get_prediction\n",
    "    parameters:\n",
    "      - img_path - path of the input image\n",
    "      - confidence - threshold value for prediction score\n",
    "    method:\n",
    "      - Image is obtained from the image path\n",
    "      - the image is converted to image tensor using PyTorch's Transforms\n",
    "      - image is passed through the model to get the predictions\n",
    "      - class, box coordinates are obtained, but only prediction score > threshold\n",
    "        are chosen.\n",
    "    \n",
    "  \"\"\"\n",
    "  img = Image.open(img_path)\n",
    "  transform = T.Compose([T.ToTensor()])\n",
    "  img = transform(img)\n",
    "  pred = model([img])\n",
    "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "  pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "  pred_t = [pred_score.index(x) for x in pred_score if x>confidence]\n",
    "  if(len(pred_t) == 0):\n",
    "    return [], []\n",
    "  pred_t = pred_t[-1]\n",
    "  pred_boxes = pred_boxes[:pred_t+1]\n",
    "  pred_class = pred_class[:pred_t+1]\n",
    "  return pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(img_path, confidence=0.5, rect_th=2, text_size=2, text_th=2):\n",
    "  \"\"\"\n",
    "  object_detection_api\n",
    "    parameters:\n",
    "      - img_path - path of the input image\n",
    "      - confidence - threshold value for prediction score\n",
    "      - rect_th - thickness of bounding box\n",
    "      - text_size - size of the class label text\n",
    "      - text_th - thichness of the text\n",
    "    method:\n",
    "      - prediction is obtained from get_prediction method\n",
    "      - for each prediction, bounding box is drawn and text is written \n",
    "        with opencv\n",
    "      - the final image is displayed\n",
    "  \"\"\"\n",
    "  image = cv2.imread(img_path)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  height, width = image.shape[0:2]\n",
    "  cow_count = 0\n",
    "  num_slice = 4\n",
    "  slices = image_slicer.slice(img_path, num_slice)\n",
    "  num_slice = len(slices)\n",
    "  \n",
    "  \n",
    "  dim =  int(np.sqrt(num_slice))\n",
    "  sheight = height // dim\n",
    "  swidth = width // dim\n",
    "\n",
    "\n",
    "  image_coordinates = []\n",
    "\n",
    "  for i in range(0, dim):\n",
    "    for j in range(0, dim):\n",
    "      sliced = slices[i * dim + j]\n",
    "      sliced_path = sliced.generate_filename(prefix=img_path[:-4], path=False)\n",
    "      boxes, pred_cls = get_prediction(sliced_path, confidence)\n",
    "      for k in range(len(boxes)):\n",
    "        if pred_cls[k] in DESIRED_CLASS:\n",
    "          cow_count += 1\n",
    "          c1 = (int(boxes[k][0][0] + j * swidth), int(boxes[k][0][1] + i * sheight))\n",
    "          c2 = (int(boxes[k][1][0] + j * swidth), int(boxes[k][1][1] + i * sheight))\n",
    "          mid_x = (c2[0] + c1[0]) // 2\n",
    "          mid_y = (c2[1] + c1[1]) // 2\n",
    "          image_coordinates.append([mid_x, mid_y])\n",
    "          cv2.rectangle(image, c1, c2, color=(0, 255, 0), thickness=rect_th)\n",
    "          cv2.putText(image, 'cow', c1, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
    "      os.remove(sliced_path)\n",
    "  # plt.figure(figsize=(20, 30))\n",
    "  # plt.imshow(image)\n",
    "  return image, cow_count, image_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"cow_images/Fall (cow)/TW4_C1_SW (09012019).JPG\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im, cow_count = detect_object(img_dir, confidence=0.6)\n",
    "# cow_image, cow_count, image_coordinates = detect_object(img_dir, confidence=0.4)\n",
    "# print(\"%d number of cows detected\" %(cow_count))\n",
    "# print(\"Image coordinates: \", image_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [28:43<00:00, 31.34s/it]\n",
      "100%|██████████| 50/50 [26:36<00:00, 31.93s/it]t]\n",
      "100%|██████████| 10/10 [05:32<00:00, 33.26s/it]t]\n",
      "100%|██████████| 12/12 [06:39<00:00, 33.31s/it]/it]\n",
      "100%|██████████| 49/49 [24:59<00:00, 30.60s/it]]   \n",
      "100%|██████████| 39/39 [21:55<00:00, 33.73s/it]t]\n",
      "100%|██████████| 53/53 [19:51<00:00, 22.48s/it]t]\n",
      "100%|██████████| 26/26 [14:14<00:00, 32.85s/it]t]\n",
      "100%|██████████| 8/8 [2:28:32<00:00, 1114.07s/it]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "f = open(\"./fasterrcnn_result.txt\", 'w')\n",
    "for folders in tqdm.tqdm(os.listdir(\"cow_images\")):\n",
    "    for files in tqdm.tqdm(os.listdir(\"cow_images/\" + folders)):\n",
    "        folder_dir = \"cow_images/\" + folders + \"/\"\n",
    "        file_dir = \"cow_images/\" + folders + \"/\" + files\n",
    "        if os.path.exists(file_dir):\n",
    "            cow_image, cow_count, image_coordinates = detect_object(file_dir, confidence=0.4)\n",
    "            new_file_dir = file_dir.replace(\"cow_images\", \"cow_images_box\")\n",
    "            cv2.imwrite(new_file_dir, cow_image)\n",
    "            data.append([new_file_dir, cow_count, image_coordinates])\n",
    "            f.write(\"%s, %d\" % (new_file_dir, cow_count))\n",
    "            for pt in image_coordinates:\n",
    "                f.write(\", (%d, %d)\" % (pt[0], pt[1]))\n",
    "            f.write(\"\\n\")\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5606/4000743260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"./fasterrcnn_result.txt\", 'w')\n",
    "# for im in data:\n",
    "#     f.write(\"%s, %d\" % (im[0], im[1]))\n",
    "#     for pt in im[2]:\n",
    "#         f.write(\", (%d, %4essee eddddedxd)\" % (pt[0], pt[1]))\n",
    "#     f.write(\"\\n\")\n",
    "# f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = cv2.imread(img_dir)\n",
    "cv2.imwrite(\"cow_images_box/Fall (cow)/TW2_C1_S.JPG\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./result1.csv\", 'w') as f:\n",
    "    f.write(\"Image Directories, Count\\n\")\n",
    "    for result in res:\n",
    "        res_dir = result[0]\n",
    "        res_count = result[1]\n",
    "        res_dir = res_dir[11:]\n",
    "        print(res_dir, res_count)\n",
    "        f.write(\"%s, %d\\n\" % (res_dir, int(res_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
