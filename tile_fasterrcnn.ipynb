{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Cow Recognition - Cow Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import numpy as np \n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import image_slicer\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and presets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basically loads the pretrained faster rcnn resnet50 model from the torch vision library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# send to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# load the COCO dataset category names\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# we want to capture anything that may looks like a cow in the wildlife\n",
    "DESIRED_CLASS = [\n",
    "    'cat',\n",
    "    'dog',\n",
    "    'horse',\n",
    "    'sheep',\n",
    "    'cow',\n",
    "    'elephant',\n",
    "    'bear',\n",
    "    'zebra',\n",
    "    'giraffe',\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, confidence):\n",
    "  \"\"\"\n",
    "  get_prediction\n",
    "    parameters:\n",
    "      - img_path - path of the input image\n",
    "      - confidence - threshold value for prediction score\n",
    "    method:\n",
    "      - Image is obtained from the image path\n",
    "      - the image is converted to image tensor using PyTorch's Transforms\n",
    "      - image is passed through the model to get the predictions\n",
    "      - class, box coordinates are obtained, but only prediction score > threshold\n",
    "        are chosen.\n",
    "    \n",
    "  \"\"\"\n",
    "\n",
    "  # read image and transform to tensor\n",
    "  img = Image.open(img_path)\n",
    "  transform = T.Compose([T.ToTensor()])\n",
    "  img = transform(img).to(device)\n",
    "\n",
    "  # put into the model\n",
    "  pred = model([img])\n",
    "\n",
    "  # read the predicted class and box\n",
    "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].detach().cpu().numpy())]\n",
    "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]\n",
    "  pred_score = list(pred[0]['scores'].detach().cpu().numpy())\n",
    "\n",
    "  # filter out those objects that are below the confidence\n",
    "  pred_t = [pred_score.index(x) for x in pred_score if x>confidence]\n",
    "  if(len(pred_t) == 0):\n",
    "    return [], []\n",
    "  pred_t = pred_t[-1]\n",
    "  pred_boxes = pred_boxes[:pred_t+1]\n",
    "  pred_class = pred_class[:pred_t+1]\n",
    "  return pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(img_path, confidence=0.5, rect_th=2, text_size=2, text_th=2):\n",
    "  \"\"\"\n",
    "  object_detection_api\n",
    "    parameters:\n",
    "      - img_path - path of the input image\n",
    "      - confidence - threshold value for prediction score\n",
    "      - rect_th - thickness of bounding box\n",
    "      - text_size - size of the class label text\n",
    "      - text_th - thichness of the text\n",
    "    method:\n",
    "      - prediction is obtained from get_prediction method\n",
    "      - for each prediction, bounding box is drawn and text is written \n",
    "        with opencv\n",
    "      - the final image is displayed\n",
    "  \"\"\"\n",
    "  # Read the image\n",
    "  image = cv2.imread(img_path)\n",
    "  HEIGHT, WIDTH = image.shape[0:2]\n",
    "  cow_count = 0\n",
    "\n",
    "  # Slice the images into defined slices\n",
    "  num_slice = 4\n",
    "  slices = image_slicer.slice(img_path, num_slice)\n",
    "  num_slice = len(slices)\n",
    "  \n",
    "  \n",
    "  dim =  int(np.sqrt(num_slice))\n",
    "  sheight = HEIGHT // dim\n",
    "  swidth = WIDTH // dim\n",
    "\n",
    "\n",
    "  image_coordinates = []\n",
    "\n",
    "  # predict for each slice\n",
    "  for i in range(0, dim):\n",
    "    for j in range(0, dim):\n",
    "      # get the slcied image\n",
    "      sliced = slices[i * dim + j]\n",
    "      sliced_path = sliced.generate_filename(prefix=img_path[:-4], path=False)\n",
    "\n",
    "      # predict the selected slice\n",
    "      boxes, pred_cls = get_prediction(sliced_path, confidence)\n",
    "\n",
    "      # for each box, draw to the original image\n",
    "      for k in range(len(boxes)):\n",
    "        if pred_cls[k] in DESIRED_CLASS:\n",
    "          cow_count += 1\n",
    "          c1 = (int(boxes[k][0][0] + j * swidth), int(boxes[k][0][1] + i * sheight))\n",
    "          c2 = (int(boxes[k][1][0] + j * swidth), int(boxes[k][1][1] + i * sheight))\n",
    "          mid_x = (c2[0] + c1[0]) // 2\n",
    "          mid_y = (c2[1] + c1[1]) // 2\n",
    "          image_coordinates.append([mid_x, mid_y])\n",
    "          cv2.rectangle(image, c1, c2, color=(0, 255, 0), thickness=rect_th)\n",
    "          cv2.putText(image, 'cow', c1, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th)\n",
    "\n",
    "      # remove the sliced image from the directory\n",
    "      os.remove(sliced_path)\n",
    "  return image, cow_count, image_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "DATA_DIR = \"cow_images\"\n",
    "CONFIDENCE = 0.42\n",
    "OUTPUT_IMAGE_DIR = \"cow_boxed\"\n",
    "OUTPUT_RESULT_DIR = \"./cow_count_output.txt\"\n",
    "if not os.path.exists(OUTPUT_IMAGE_DIR):\n",
    "    os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "\n",
    "# write to the result text\n",
    "f = open(OUTPUT_RESULT_DIR, 'w')\n",
    "# loop through all the images\n",
    "for folders in tqdm.tqdm(os.listdir(DATA_DIR)):\n",
    "    for files in os.listdir(f\"{DATA_DIR}/{folders}\"):\n",
    "        folder_dir = f\"{DATA_DIR}/{folders}/\"\n",
    "        file_dir = f\"{DATA_DIR}/{folders}/{files}\"\n",
    "        # check to see if the file exists\n",
    "        if os.path.exists(file_dir):\n",
    "            cow_image, cow_count, image_coordinates = detect_object(file_dir, confidence=CONFIDENCE)\n",
    "            new_file_dir = file_dir.replace(\"cow_images\", OUTPUT_IMAGE_DIR)\n",
    "            # Write the new boxed images\n",
    "            cv2.imwrite(new_file_dir, cow_image)\n",
    "            data.append([new_file_dir, cow_count, image_coordinates])\n",
    "            # Write the result to the file\n",
    "            f.write(\"%s, %d\" % (new_file_dir, cow_count))\n",
    "            for pt in image_coordinates:\n",
    "                f.write(\", (%d, %d)\" % (pt[0], pt[1]))\n",
    "            f.write(\"\\n\")\n",
    "f.close() \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
